{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project - AWS ETL Data Streaming \n",
    "We decided to create a Data Pipeline on AWS that could facilitate the process of building a Natural Language Processing tool. The tool will utilize a simple machine learning algorithm or one/two layer neural network to train a topic modeler or sentiment analyzer or a recommender. The technologies (tentative) that will be used in this project\n",
    "\n",
    "* Terraform to create template for cloud managment and configuration \n",
    "* Lambda and SAM to streamline a simple ETL data pipeline that extracts, processes, and load the data from Twitter API(tentative)\n",
    "* Eventbridge(Cloudwatch events) to log and monitor state changes \n",
    "* S3 Bucket to store the raw retrieved data (potentially utilize DynamoDB to store the parsed and processed data for future analytics)\n",
    "* Sagemaker to create a notebook for hosting the ML project code, fine-tuning  parameters, pipelining and storing the models\n",
    "* Pandas to ingest and wrangle the data and preprocess it for ML training\n",
    "* EC2 to create a VM that hosts the workflow or provide workers for training if needed \n",
    "* (Tentative) DynamoDB to store a structured version of the output data for future reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terraform templapte \n",
    "to create  and manage an aws infrastructure \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run test code for Terraform templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/shiyishen/nlp/aws-data-engineering/aws-data-pipeline/cdk-tf/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies and packages for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3\n",
    "!pip install awswrangler\n",
    "!pip install tweepy\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data streaming with Lambda from Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Cannot get rules (HTTP 401): {\n  \"title\": \"Unauthorized\",\n  \"type\": \"about:blank\",\n  \"status\": 401,\n  \"detail\": \"Unauthorized\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/slkwc76100z5hk0tb6tlg5q40000gn/T/ipykernel_68619/1742453535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/db/slkwc76100z5hk0tb6tlg5q40000gn/T/ipykernel_68619/1742453535.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mdelete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelete_all_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/db/slkwc76100z5hk0tb6tlg5q40000gn/T/ipykernel_68619/1742453535.py\u001b[0m in \u001b[0;36mget_rules\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         raise Exception(\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;34m\"Cannot get rules (HTTP {}): {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         )\n",
      "\u001b[0;31mException\u001b[0m: Cannot get rules (HTTP 401): {\n  \"title\": \"Unauthorized\",\n  \"type\": \"about:blank\",\n  \"status\": 401,\n  \"detail\": \"Unauthorized\"\n}"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "bearer_token = os.environ.get(\"AAAAAAAAAAAAAAAAAAAAADJKhwEAAAAA%2BkjQU9%2BBJPu%2FX5QrarVf9ppyAfE%3D99qn5c6SvhI9vegVNJax3Lo4jRqZWWqOYzsMNrTVHQNDO8CqNU\")\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2FilteredStreamPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_rules():\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", auth=bearer_oauth\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def delete_all_rules(rules):\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        auth=bearer_oauth,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "\n",
    "def set_rules(delete):\n",
    "    # You can adjust the rules if needed\n",
    "    sample_rules = [\n",
    "        {\"value\": \"election place_country:US\"},\n",
    "        {\"value\": \"political\"},\n",
    "    ]\n",
    "    payload = {\"add\": sample_rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        auth=bearer_oauth,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "\n",
    "def get_stream(set):\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\", auth=bearer_oauth, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    for response_line in response.iter_lines():\n",
    "        if response_line:\n",
    "            json_response = json.loads(response_line)\n",
    "            print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "def main():\n",
    "    rules = get_rules()\n",
    "    delete = delete_all_rules(rules)\n",
    "    set = set_rules(delete)\n",
    "    get_stream(set)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Twitter pulling class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter processing class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter loading class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling and transformation with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Machine Learning LDA Algorithm on EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker imports \n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83dad2faf6f2abb98f4e58cfd44768f1d23e620e50d8b5bb3c0bd70ec1d7354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
